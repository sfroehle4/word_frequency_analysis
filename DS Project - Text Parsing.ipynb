{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency in Peter Pan by J.M. Barrie\n",
    "## Introduction\n",
    "\n",
    "### In this project I used the Python requests package to scrape the novel Peter Pan by J.M. Barrie from the Project Gutenberg site. I then used Beautiful Soup to extract the words from the HTML file. I used nltk to process the file and Counter to count occurrences of each word.\n",
    "\n",
    "### This project comes from DataCamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Imports\n",
    "### For this project the following imports were used:\n",
    "1. requests: Python package used for making HTTP requests\n",
    "2. BeautifulSoup from bs4: Python package for parsing HTML and XML documents\n",
    "3. nltk: Natural Language Tool Kit used for processing human language\n",
    "4. Counter from collections: Collection used to get the count of items, for this project a count of words/occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import HTML file and extract the text from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving the Peter Pan HTML\n",
    "r = requests.get('https://www.gutenberg.org/cache/epub/16/pg16-images.html')\n",
    "\n",
    "#Setting the correct text encoding of the HTML page\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "#Extracting the HTML from the request object\n",
    "html = r.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a BeautifulSoup object from the HTML\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "#Get the text out of the soup\n",
    "text = soup.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "### To prepare this data the following steps were taken: \n",
    "1. tokenize the text into individual words\n",
    "2. turn all words to lowercase to make processing easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook',\n",
       " 'of',\n",
       " 'Peter',\n",
       " 'Pan',\n",
       " 'by',\n",
       " 'James',\n",
       " 'M',\n",
       " 'Barrie']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "\n",
    "#Tokenize the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "#Print out the first few words/tokens\n",
    "tokens[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'peter',\n",
       " 'pan',\n",
       " 'by',\n",
       " 'james',\n",
       " 'm',\n",
       " 'barrie']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a list called words containing all tokens transformed to lowercase\n",
    "words = [token.lower() for token in tokens]\n",
    "\n",
    "#Print out the first 11 words/tokens\n",
    "words[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords\n",
    "### Stopwords are common words used in English that should not necessarily be counted, like \"the,\" \"and,\" or \"or.\" For this project, stopwords were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sfroe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['project', 'gutenberg', 'ebook', 'peter', 'pan']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download the stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Getting the English stop words from nltk\n",
    "sw = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#Create a list of words that are in words but not in stopwords\n",
    "words_ns = [word for word in words if word not in sw]\n",
    "\n",
    "#Print the first 5 words to confirm the stopwords are gone\n",
    "words_ns[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The Answer\n",
    "\n",
    "### Getting the answer involved counting the occurence of each word and then populating the most frequently used word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('peter', 408), ('wendy', 361), ('said', 358), ('would', 217), ('one', 212), ('hook', 174), ('could', 142), ('cried', 136), ('john', 133), ('time', 126)]\n"
     ]
    }
   ],
   "source": [
    "#Initialize a Counter object from our processed list of words\n",
    "count = Counter(words_ns)\n",
    "\n",
    "#Store 10 most common words and their counts as top_ten\n",
    "top_ten = count.most_common(10)\n",
    "\n",
    "#Print the top ten words and their counts\n",
    "print(top_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common word in Peter Pan is peter and it occurs 408 times.\n"
     ]
    }
   ],
   "source": [
    "#What's the most common word in Peter Pan?\n",
    "print(\"The most common word in Peter Pan is\", top_ten[0][0], \"and it occurs\", top_ten[0][1], \"times.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
